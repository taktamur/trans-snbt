import os
import sys
import json
import re
import time
import shutil
from glob import glob
from typing import List, Dict, Optional, Tuple
import anthropic
import difflib

def load_all_json():
    """all.jsonã‚’èª­ã¿è¾¼ã‚€ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦ä½œæˆã™ã‚‹"""
    if os.path.exists('all.json'):
        with open('all.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    return {"descriptions": []}

def save_all_json(data):
    """all.jsonã‚’ä¿å­˜ã™ã‚‹"""
    with open('all.json', 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def extract_descriptions(content):
    """SNBTãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰descriptionã‚’æŠ½å‡ºã™ã‚‹"""
    pattern = r'description: \[([\s\S]*?)\]'
    matches = re.finditer(pattern, content)
    descriptions = []
    
    for match in matches:
        # descriptioné…åˆ—ã®å†…å®¹ã‚’å–å¾—
        desc_content = match.group(1).strip()
        # å„è¡Œã‚’å‡¦ç†
        lines = [line.strip().strip('"') for line in desc_content.split('\n')]
        # ç©ºæ–‡å­—ã¨ã‚¹ãƒšãƒ¼ã‚¹ã®ã¿ã®è¡Œã‚’é™¤å¤–
        non_empty_lines = [line for line in lines if line and not line.isspace()]
        descriptions.extend(non_empty_lines)
    
    return descriptions

def create_backup(file_path: str) -> bool:
    """SNBTãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã™ã‚‹
    
    Args:
        file_path: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        bool: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    backup_path = f"{file_path}.bak"
    
    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒæ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ä½œæˆã—ãªã„
    if os.path.exists(backup_path):
        print(f"â„¹ï¸ {os.path.basename(backup_path)} ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™")
        return False
    
    try:
        shutil.copy2(file_path, backup_path)
        print(f"âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆã—ã¾ã—ãŸ: {os.path.basename(backup_path)}")
        return True
    except Exception as e:
        print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        return False

def process_snbt_files(directory):
    """SNBTãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹"""
    # all.jsonã‚’èª­ã¿è¾¼ã‚€
    all_data = load_all_json()
    existing_descriptions = {item["en"]: item for item in all_data["descriptions"]}
    
    # SNBTãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
    snbt_files = glob(os.path.join(directory, "*.snbt"))
    for snbt_file in snbt_files:
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
        create_backup(snbt_file)
        filename = os.path.basename(snbt_file)
        print(f"ğŸ“„ {filename} ã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        
        try:
            with open(snbt_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # descriptionã‚’æŠ½å‡º
            descriptions = extract_descriptions(content)
            
            # æ–°ã—ã„èª¬æ˜æ–‡ã‚’è¿½åŠ 
            for desc in descriptions:
                # ç©ºæ–‡å­—ã¯é™¤å¤–
                if desc and desc not in existing_descriptions:
                    new_entry = {
                        "file": filename,
                        "en": desc,
                        "ja": ""
                    }
                    all_data["descriptions"].append(new_entry)
                    existing_descriptions[desc] = new_entry
        
        except Exception as e:
            print(f"âŒ {filename} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            continue
    
    # æ›´æ–°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    save_all_json(all_data)
    print("\nâœ… ãƒ•ã‚§ãƒ¼ã‚º1ãŒå®Œäº†ã—ã¾ã—ãŸ")
    print("ğŸ“ all.json ãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ")

def get_untranslated_entries(data: Dict) -> List[Dict]:
    """æœªç¿»è¨³ã®ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—ã™ã‚‹"""
    # ç©ºã®enæ–‡å­—åˆ—ã¯é™¤å¤–ã—ã€æœªç¿»è¨³ã®ã‚¨ãƒ³ãƒˆãƒªã®ã¿ã‚’è¿”ã™
    return [entry for entry in data["descriptions"] if entry["ja"] == "" and entry["en"]]

def chunk_entries(entries: List[Dict], chunk_size: int = 10) -> List[List[Dict]]:
    """ã‚¨ãƒ³ãƒˆãƒªã‚’æŒ‡å®šã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹"""
    return [entries[i:i + chunk_size] for i in range(0, len(entries), chunk_size)]

# ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
CLAUDE_MODEL = "claude-3-5-haiku-20241022"

def create_claude_client() -> anthropic.Anthropic:
    """Claude APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆã™ã‚‹"""
    api_key = os.getenv('ANTHROPIC_API_KEY')
    if not api_key:
        raise ValueError("ANTHROPIC_API_KEY environment variable is not set")
    return anthropic.Anthropic(api_key=api_key)

def translate_with_claude(client: anthropic.Anthropic, text: str) -> Optional[str]:
    """Claude APIã‚’ä½¿ç”¨ã—ã¦ç¿»è¨³ã‚’è¡Œã†"""
    try:
        # ç¿»è¨³ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        prompt = f"""
ã‚ãªãŸã¯Minecraftã®modpackã®ã‚¯ã‚¨ã‚¹ãƒˆãƒ–ãƒƒã‚¯ã®ç¿»è¨³ã‚’æ‹…å½“ã—ã¦ã„ã¾ã™ã€‚
ä»¥ä¸‹ã®è‹±æ–‡ã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚ã‚²ãƒ¼ãƒãƒ¼ã«ã¨ã£ã¦è‡ªç„¶ãªæ—¥æœ¬èªã«ãªã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
&aãªã©ã®Minecraftç‰¹æ®Šè¨˜æ³•ã¯ãã®ã¾ã¾ä¿æŒã—ã¦ãã ã•ã„ã€‚

è‹±æ–‡: {text}

ç¿»è¨³æ–‡ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""
        
        # ç¿»è¨³ã‚’å®Ÿè¡Œ
        response = client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=1000,
            temperature=0,
            system="You are a professional translator specializing in Minecraft and gaming content.",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.content[0].text.strip()
    
    except Exception as e:
        print(f"âŒ ç¿»è¨³ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def translate_entries(entries: List[Dict]) -> None:
    """ã‚¨ãƒ³ãƒˆãƒªã‚’ç¿»è¨³ã™ã‚‹"""
    try:
        client = create_claude_client()
        for entry in entries:
            print(f"ğŸ”„ ç¿»è¨³ä¸­: {entry['en']}")
            translated = translate_with_claude(client, entry['en'])
            
            if translated:
                entry['ja'] = translated
                print(f"âœ… ç¿»è¨³å®Œäº†: {translated}")
            else:
                entry['ja'] = ""
                print("âŒ ç¿»è¨³ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ¬¡å›ã®å®Ÿè¡Œæ™‚ã«å†è©¦è¡Œã—ã¾ã™")
            
            # APIãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å°‘ã—å¾…æ©Ÿ
            time.sleep(1)
    
    except Exception as e:
        print(f"âŒ ç¿»è¨³å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

def show_diff(old_content: str, new_content: str, filename: str) -> None:
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®å·®åˆ†ã‚’è¡¨ç¤ºã™ã‚‹
    
    Args:
        old_content: å¤‰æ›´å‰ã®å†…å®¹
        new_content: å¤‰æ›´å¾Œã®å†…å®¹
        filename: ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆè¡¨ç¤ºç”¨ï¼‰
    """
    # å·®åˆ†ã‚’è¨ˆç®—
    diff = list(difflib.unified_diff(
        old_content.splitlines(keepends=True),
        new_content.splitlines(keepends=True),
        fromfile=f"{filename} (å¤‰æ›´å‰)",
        tofile=f"{filename} (å¤‰æ›´å¾Œ)",
        n=3  # å‰å¾Œ3è¡Œã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
    ))
    
    if diff:
        print(f"\nğŸ“Š {filename} ã®å¤‰æ›´å†…å®¹:")
        for line in diff:
            # å‰Šé™¤è¡Œã¯èµ¤ã€è¿½åŠ è¡Œã¯ç·‘ã§è¡¨ç¤º
            if line.startswith('+'):
                print(f"\033[92m{line}\033[0m", end='')  # ç·‘è‰²
            elif line.startswith('-'):
                print(f"\033[91m{line}\033[0m", end='')  # èµ¤è‰²
            else:
                print(line, end='')
        print()  # ç©ºè¡Œã‚’è¿½åŠ 
    else:
        print(f"â„¹ï¸ {filename} ã«å¤‰æ›´ã¯ã‚ã‚Šã¾ã›ã‚“")

def apply_translations(file_path: str, translations: Dict) -> bool:
    """ç¿»è¨³æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆã‚’SNBTãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨ã™ã‚‹
    
    Args:
        file_path: æ›´æ–°ã™ã‚‹SNBTãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        translations: ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ï¼ˆall.jsonã®å†…å®¹ï¼‰
        
    Returns:
        bool: æ›´æ–°ãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    try:
        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å†…å®¹ã‚’èª­ã¿è¾¼ã‚€
        backup_path = f"{file_path}.bak"
        with open(backup_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«å¯¾å¿œã™ã‚‹ç¿»è¨³ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—
        filename = os.path.basename(file_path)
        file_translations = {
            entry["en"]: entry["ja"]
            for entry in translations["descriptions"]
            if entry["file"] == filename and entry["ja"]
        }
        
        if not file_translations:
            print(f"â„¹ï¸ {filename} ã®ç¿»è¨³ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        # descriptionãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œå‡ºã—ã¦ç¿»è¨³ã‚’é©ç”¨
        def replace_description(match):
            desc_content = match.group(0)  # description: [...]å…¨ä½“ã‚’å–å¾—
            for en, ja in file_translations.items():
                # è‹±èªãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¥æœ¬èªã«ç½®æ›ï¼ˆå¼•ç”¨ç¬¦ä»˜ãã§æ¤œç´¢ãƒ»ç½®æ›ï¼‰
                desc_content = desc_content.replace(f'"{en}"', f'"{ja}"')
            return desc_content
        
        # ç¿»è¨³ã‚’é©ç”¨
        pattern = r'description: \[([\s\S]*?)\]'
        updated_content = re.sub(pattern, replace_description, content)
        
        # å·®åˆ†ã‚’è¡¨ç¤ºï¼ˆæ›´æ–°å‰ã¨æ›´æ–°å¾Œã®å†…å®¹ã‚’æ¯”è¼ƒï¼‰
        show_diff(content, updated_content, filename)
        
        # å¤‰æ›´ãŒã‚ã‚‹å ´åˆã®ã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        if updated_content != content:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(updated_content)
            print(f"âœ… {filename} ã®ç¿»è¨³ã‚’é©ç”¨ã—ã¾ã—ãŸ")
            return True
        return False
            
    except Exception as e:
        print(f"âŒ {filename} ã®æ›´æ–°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return False

def process_translations():
    """ç¿»è¨³å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹"""
    # all.jsonã‚’èª­ã¿è¾¼ã‚€
    all_data = load_all_json()
    
    # æœªç¿»è¨³ã‚¨ãƒ³ãƒˆãƒªã‚’å–å¾—
    untranslated = get_untranslated_entries(all_data)
    if not untranslated:
        print("âœ¨ æœªç¿»è¨³ã®ã‚¨ãƒ³ãƒˆãƒªã¯ã‚ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ” {len(untranslated)}ä»¶ã®æœªç¿»è¨³ã‚¨ãƒ³ãƒˆãƒªã‚’è¦‹ã¤ã‘ã¾ã—ãŸ")
    
    # 10ã‚¨ãƒ³ãƒˆãƒªã”ã¨ã«å‡¦ç†
    chunks = chunk_entries(untranslated)
    for i, chunk in enumerate(chunks, 1):
        print(f"\nğŸ“š ãƒãƒ£ãƒ³ã‚¯ {i}/{len(chunks)} ã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        translate_entries(chunk)
        
        # 10ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        save_all_json(all_data)
        print(f"ğŸ’¾ é€²æ—ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚{i * 10 if i < len(chunks) else len(untranslated)}ä»¶å®Œäº†")

def parse_args():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‚’ãƒ‘ãƒ¼ã‚¹ã™ã‚‹"""
    import argparse
    parser = argparse.ArgumentParser(description='SNBTãƒ•ã‚¡ã‚¤ãƒ«ã®ç¿»è¨³å‡¦ç†')
    parser.add_argument('directory', help='SNBTãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹')
    parser.add_argument('-p', '--phase',
                        choices='123',
                        help='å®Ÿè¡Œã™ã‚‹ãƒ•ã‚§ãƒ¼ã‚ºã‚’æŒ‡å®šï¼ˆ1: SNBTæŠ½å‡º, 2: ç¿»è¨³, 3: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼‰ã€‚çœç•¥æ™‚ã¯å…¨ãƒ•ã‚§ãƒ¼ã‚ºã‚’å®Ÿè¡Œ')
    return parser.parse_args()

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    args = parse_args()
    
    if not os.path.isdir(args.directory):
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {args.directory} ã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    # Phase 2ã®ã¿å®Ÿè¡Œæ™‚ã®è­¦å‘Š
    if args.phase == '2' and not os.path.exists('all.json'):
        print("âš ï¸ è­¦å‘Š: all.jsonãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚Phase 1ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        sys.exit(1)
    
    # ãƒ•ã‚§ãƒ¼ã‚ºã®å®Ÿè¡Œåˆ¶å¾¡
    if not args.phase or args.phase == '1':
        process_snbt_files(args.directory)
    
    if not args.phase or args.phase == '2':
        process_translations()
    
    if not args.phase or args.phase == '3':
        print("\nğŸ“ ãƒ•ã‚§ãƒ¼ã‚º3: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ç¿»è¨³é©ç”¨ã‚’é–‹å§‹ã—ã¾ã™...")
        
        # all.jsonã‚’èª­ã¿è¾¼ã‚€
        all_data = load_all_json()
        
        # SNBTãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        snbt_files = glob(os.path.join(args.directory, "*.snbt"))
        for snbt_file in snbt_files:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®å­˜åœ¨ç¢ºèªã®ã¿è¡Œã„ã€ç¿»è¨³ã¯å¸¸ã«é©ç”¨ã™ã‚‹
            create_backup(snbt_file)
            apply_translations(snbt_file, all_data)

if __name__ == "__main__":
    main()
